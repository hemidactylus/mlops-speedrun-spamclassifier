{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e5224d9",
   "metadata": {},
   "source": [
    "# Training of the LSTM \"v2\" model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ca0c7",
   "metadata": {},
   "source": [
    "## Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fdf89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:00:26.450296: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-30 17:00:26.450321: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from feast import FeatureStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce91f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(os.getcwd(), '..', '..')\n",
    "store_dir = os.path.join(root_dir, 'sms_feature_store')\n",
    "raw_data_dir = os.path.join(root_dir, 'raw_data')\n",
    "model_save_dir = os.path.join(root_dir, 'models', 'model2_2020', 'classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d8b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "input_dir = os.path.join(base_dir, '..', '..',  'models', 'model2_2020', 'tokenizer')\n",
    "input_metadata_file = os.path.join(input_dir, 'settings.json')\n",
    "tokenizer_settings = json.load(open(input_metadata_file))\n",
    "MAX_NUM_WORDS = tokenizer_settings['MAX_NUM_WORDS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65b5723c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 128\n",
    "LSTM_OUT_DIM = 196\n",
    "SPATIAL_DROPOUT_FRACTION = 0.4\n",
    "LSTM_DROPOUT_FRACTION = 0.3\n",
    "LSTM_RECURRENT_DROPOUT_FRACTION = 0.3\n",
    "#\n",
    "SPLIT_TEST_SIZE = 0.25\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TRAIN_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c29918f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing time to 2020-07-02 00:00:00 for training\n"
     ]
    }
   ],
   "source": [
    "training_timefreeze = datetime.datetime(2020, 7, 2)\n",
    "print(f\"Freezing time to {training_timefreeze.strftime('%Y-%m-%d %H:%M:%S')} for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed973f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = FeatureStore(repo_path=store_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4391d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sms_ids = [\n",
    "    int(sms_id)\n",
    "    for sms_id in (\n",
    "        line.strip()\n",
    "        for line in open(os.path.join(raw_data_dir, 'training_sms_ids.txt')).readlines()\n",
    "    )\n",
    "    if sms_id\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d30518c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df = pandas.DataFrame.from_dict({\n",
    "    'sms_id': training_sms_ids,\n",
    "})\n",
    "entities_df['event_timestamp'] = training_timefreeze\n",
    "\n",
    "historical_df = store.get_historical_features(\n",
    "    entity_df=entities_df,\n",
    "    features=[\n",
    "        'sms_labels:label',\n",
    "        'sms_features2:features',\n",
    "    ],\n",
    ").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d202ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms_id</th>\n",
       "      <th>event_timestamp</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>2020-07-02 00:00:00+00:00</td>\n",
       "      <td>ham</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10028</td>\n",
       "      <td>2020-07-02 00:00:00+00:00</td>\n",
       "      <td>ham</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 147, 3, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10027</td>\n",
       "      <td>2020-07-02 00:00:00+00:00</td>\n",
       "      <td>ham</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10002</td>\n",
       "      <td>2020-07-02 00:00:00+00:00</td>\n",
       "      <td>ham</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10003</td>\n",
       "      <td>2020-07-02 00:00:00+00:00</td>\n",
       "      <td>spam</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7523</th>\n",
       "      <td>17522</td>\n",
       "      <td>2020-07-02 00:00:00+00:00</td>\n",
       "      <td>ham</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7524</th>\n",
       "      <td>17523</td>\n",
       "      <td>2020-07-02 00:00:00+00:00</td>\n",
       "      <td>ham</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7525</th>\n",
       "      <td>17524</td>\n",
       "      <td>2020-07-02 00:00:00+00:00</td>\n",
       "      <td>ham</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7526</th>\n",
       "      <td>17512</td>\n",
       "      <td>2020-07-02 00:00:00+00:00</td>\n",
       "      <td>spam</td>\n",
       "      <td>[0, 0, 0, 0, 0, 34, 5, 27, 32, 122, 122, 122, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>17528</td>\n",
       "      <td>2020-07-02 00:00:00+00:00</td>\n",
       "      <td>ham</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7528 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sms_id           event_timestamp label  \\\n",
       "0      10001 2020-07-02 00:00:00+00:00   ham   \n",
       "1      10028 2020-07-02 00:00:00+00:00   ham   \n",
       "2      10027 2020-07-02 00:00:00+00:00   ham   \n",
       "3      10002 2020-07-02 00:00:00+00:00   ham   \n",
       "4      10003 2020-07-02 00:00:00+00:00  spam   \n",
       "...      ...                       ...   ...   \n",
       "7523   17522 2020-07-02 00:00:00+00:00   ham   \n",
       "7524   17523 2020-07-02 00:00:00+00:00   ham   \n",
       "7525   17524 2020-07-02 00:00:00+00:00   ham   \n",
       "7526   17512 2020-07-02 00:00:00+00:00  spam   \n",
       "7527   17528 2020-07-02 00:00:00+00:00   ham   \n",
       "\n",
       "                                               features  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 147, 3, 5...  \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "7523  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "7524  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "7525  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "7526  [0, 0, 0, 0, 0, 34, 5, 27, 32, 122, 122, 122, ...  \n",
       "7527  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[7528 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46fc57a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e22c9",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3fd3f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelLegend: {'ham': 0, 'spam': 1}\n",
      "labelLegendInverted: {'0': 'ham', '1': 'spam'}\n"
     ]
    }
   ],
   "source": [
    "labelLegend = {\n",
    "    lb: idx\n",
    "    for idx, lb in enumerate(np.unique(historical_df['label']))\n",
    "}\n",
    "labelLegendInverted = {'%i' % v: k for k,v in labelLegend.items()}\n",
    "#\n",
    "# print(f'labels: {labels}')\n",
    "print(f'labelLegend: {labelLegend}')\n",
    "print(f'labelLegendInverted: {labelLegendInverted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57b2fbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "oneHotEncodedLabels = to_categorical(historical_df['label'].map(lambda lb: labelLegend[lb]))\n",
    "print(oneHotEncodedLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce3a0b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = [[  0   0   0 ... 169  77  68]\n",
      " [  0   0   0 ...   3   7  45]\n",
      " [  0   0   0 ...   0  18  21]\n",
      " ...\n",
      " [  0   0   0 ...  12  16   5]\n",
      " [  0   0   0 ... 122 122  19]\n",
      " [  0   0   0 ...  53   5  19]]\n",
      "\n",
      "Y = [[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = pandas.DataFrame(historical_df.features.tolist()).to_numpy()\n",
    "Y = oneHotEncodedLabels\n",
    "#\n",
    "print(f'X = {X}')\n",
    "print(f'\\nY = {Y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a17d29",
   "metadata": {},
   "source": [
    "#### Training/testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cab09d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape = (5646, 30)\n",
      "Y_train.shape = (5646, 2)\n",
      "X_test.shape = (1882, 30)\n",
      "Y_test.shape = (1882, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=SPLIT_TEST_SIZE, random_state=2022)\n",
    "#\n",
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(f'Y_train.shape = {Y_train.shape}')\n",
    "print(f'X_test.shape = {X_test.shape}')\n",
    "print(f'Y_test.shape = {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1174978",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02401ad8",
   "metadata": {},
   "source": [
    "#### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dfe0f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 17:00:45.173186: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-30 17:00:45.173209: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-30 17:00:45.173231: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (verbascum): /proc/driver/nvidia/version does not exist\n",
      "2022-08-30 17:00:45.173443: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"spam_v2_2020\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 30, 128)           23040     \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 30, 128)          0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 196)               254800    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 394       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 278,234\n",
      "Trainable params: 278,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='spam_v2_2020')\n",
    "model.add(Embedding(MAX_NUM_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(SPATIAL_DROPOUT_FRACTION))\n",
    "model.add(LSTM(LSTM_OUT_DIM, dropout=LSTM_DROPOUT_FRACTION, recurrent_dropout=LSTM_RECURRENT_DROPOUT_FRACTION))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e54b02b",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c05fa1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Training starts...\n",
      "\n",
      "Epoch 1/5\n",
      "177/177 [==============================] - 11s 54ms/step - loss: 0.2962 - accuracy: 0.8806 - val_loss: 0.1940 - val_accuracy: 0.9346\n",
      "Epoch 2/5\n",
      "177/177 [==============================] - 10s 55ms/step - loss: 0.1691 - accuracy: 0.9460 - val_loss: 0.1563 - val_accuracy: 0.9495\n",
      "Epoch 3/5\n",
      "177/177 [==============================] - 9s 53ms/step - loss: 0.1512 - accuracy: 0.9511 - val_loss: 0.1499 - val_accuracy: 0.9543\n",
      "Epoch 4/5\n",
      "177/177 [==============================] - 11s 61ms/step - loss: 0.1405 - accuracy: 0.9548 - val_loss: 0.1475 - val_accuracy: 0.9527\n",
      "Epoch 5/5\n",
      "177/177 [==============================] - 11s 62ms/step - loss: 0.1355 - accuracy: 0.9538 - val_loss: 0.1527 - val_accuracy: 0.9511\n",
      "\n",
      "** Training completed\n"
     ]
    }
   ],
   "source": [
    "print('** Training starts...\\n')\n",
    "model.fit(X_train, Y_train,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          batch_size=TRAIN_BATCH_SIZE, verbose=1,\n",
    "          epochs=TRAIN_EPOCHS)\n",
    "print('\\n** Training completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c465fb4a",
   "metadata": {},
   "source": [
    "#### Evaluate model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "799279ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "# Y_predict = model.predict(X_test)\n",
    "# # accuracy = accuracy_score(Y_test, Y_predict)\n",
    "# precision = precision_score(Y_test, Y_predict)\n",
    "# recall = recall_score(Y_test, Y_predict)\n",
    "\n",
    "# # print('Accuracy:  %.4f' % accuracy)\n",
    "# print('Precision: %.4f' % precision)\n",
    "# print('Recall:    %.4f' % recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab02ce",
   "metadata": {},
   "source": [
    "### Storing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7681cb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the trained model ...done [/home/stefano/personal/WORK_Datastax/mlops-speedrun-spamclassifier/training/model2_2020/../../models/model2_2020/classifier/model2.h5]\n",
      "Saving model metadata ...done [/home/stefano/personal/WORK_Datastax/mlops-speedrun-spamclassifier/training/model2_2020/../../models/model2_2020/classifier/model2_metadata.json]\n"
     ]
    }
   ],
   "source": [
    "print('Saving the trained model ...', end='')\n",
    "model_out_file = os.path.join(model_save_dir, 'model2.h5')\n",
    "model.save(model_out_file)\n",
    "print(f'done [{model_out_file}]')\n",
    "\n",
    "print('Saving model metadata ...', end='')\n",
    "metadata_out_file = os.path.join(model_save_dir, 'model2_metadata.json')\n",
    "#\n",
    "model_metadata = {\n",
    "    'label_legend_inverted': labelLegendInverted,\n",
    "    'label_legend': labelLegend,\n",
    "#     'max_words': MAX_NUM_WORDS,\n",
    "}\n",
    "#\n",
    "json.dump(model_metadata, open(metadata_out_file, 'w'), indent=2)\n",
    "print(f'done [{metadata_out_file}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc7a66",
   "metadata": {},
   "source": [
    "#### Test load-and-apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab98d5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 192ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ham': 0.09027307480573654, 'spam': 0.9097268581390381}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "from analysis.features2.feature2_extractor import Feature2Extractor\n",
    "\n",
    "#\n",
    "feature2_extractor = Feature2Extractor()\n",
    "loaded_model = models.load_model(model_out_file)\n",
    "loaded_metadata = json.load(open(metadata_out_file))\n",
    "\n",
    "# prediction\n",
    "input_text = 'hi guys download this shady thing if you like free cash and a prize'\n",
    "feats = feature2_extractor.get_features_list(input_text)\n",
    "probabilities = loaded_model.predict(np.array([feats]))[0].tolist()\n",
    "prediction = {\n",
    "    lb: probabilities[lbi]\n",
    "    for lb, lbi in loaded_metadata['label_legend'].items()\n",
    "}\n",
    "#\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
