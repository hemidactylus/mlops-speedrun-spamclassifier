{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab0119ec",
   "metadata": {},
   "source": [
    "# Training of the LSTM \"v2\" model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96ca0c7",
   "metadata": {},
   "source": [
    "## Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fdf89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from feast import FeatureStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce91f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.join(os.getcwd(), '..', '..')\n",
    "store_dir = os.path.join(root_dir, 'sms_feature_store')\n",
    "raw_data_dir = os.path.join(root_dir, 'raw_data')\n",
    "model_save_dir = os.path.join(root_dir, 'models', 'model2_2020', 'classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.getcwd()\n",
    "input_dir = os.path.join(base_dir, '..', '..',  'models', 'model2_2020', 'tokenizer')\n",
    "input_metadata_file = os.path.join(input_dir, 'settings.json')\n",
    "tokenizer_settings = json.load(open(input_metadata_file))\n",
    "MAX_NUM_WORDS = tokenizer_settings['MAX_NUM_WORDS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7018700",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 6\n",
    "LSTM_OUT_DIM = 6\n",
    "SPATIAL_DROPOUT_FRACTION = 0.05\n",
    "LSTM_DROPOUT_FRACTION = 0.05\n",
    "LSTM_RECURRENT_DROPOUT_FRACTION = 0.05\n",
    "#\n",
    "SPLIT_TEST_SIZE = 0.25\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "TRAIN_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c29918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_timefreeze = datetime.datetime(2020, 7, 2)\n",
    "print(f\"Freezing time to {training_timefreeze.strftime('%Y-%m-%d %H:%M:%S')} for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed973f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = FeatureStore(repo_path=store_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4391d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sms_ids = [\n",
    "    sms_id\n",
    "    for sms_id in (\n",
    "        line.strip()\n",
    "        for line in open(os.path.join(raw_data_dir, 'training_sms_ids.txt')).readlines()\n",
    "    )\n",
    "    if sms_id\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30518c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df = pandas.DataFrame.from_dict({\n",
    "    'sms_id': training_sms_ids,\n",
    "})\n",
    "entities_df['event_timestamp'] = training_timefreeze\n",
    "\n",
    "historical_df = store.get_historical_features(\n",
    "    entity_df=entities_df,\n",
    "    features=[\n",
    "        'sms_labels:label',\n",
    "        'sms_features2:features',\n",
    "    ],\n",
    ").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d202ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46fc57a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e22c9",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelLegend = {\n",
    "    lb: idx\n",
    "    for idx, lb in enumerate(np.unique(historical_df['label']))\n",
    "}\n",
    "labelLegendInverted = {'%i' % v: k for k,v in labelLegend.items()}\n",
    "#\n",
    "print(f'labelLegend: {labelLegend}')\n",
    "print(f'labelLegendInverted: {labelLegendInverted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16143c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotEncodedLabels = to_categorical(historical_df['label'].map(lambda lb: labelLegend[lb]))\n",
    "print(oneHotEncodedLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b35de9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pandas.DataFrame(historical_df.features.tolist()).to_numpy()\n",
    "Y = oneHotEncodedLabels\n",
    "#\n",
    "print(f'X = {X}')\n",
    "print(f'\\nY = {Y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24121a3",
   "metadata": {},
   "source": [
    "#### Training/testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478dc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=SPLIT_TEST_SIZE, random_state=2022)\n",
    "#\n",
    "print(f'X_train.shape = {X_train.shape}')\n",
    "print(f'Y_train.shape = {Y_train.shape}')\n",
    "print(f'X_test.shape = {X_test.shape}')\n",
    "print(f'Y_test.shape = {Y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b4338",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1d7b2",
   "metadata": {},
   "source": [
    "#### Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe0f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name='spam_v2_2020')\n",
    "model.add(Embedding(MAX_NUM_WORDS, EMBEDDING_DIM, input_length=X_train.shape[1]))\n",
    "model.add(SpatialDropout1D(SPATIAL_DROPOUT_FRACTION))\n",
    "model.add(LSTM(LSTM_OUT_DIM, dropout=LSTM_DROPOUT_FRACTION, recurrent_dropout=LSTM_RECURRENT_DROPOUT_FRACTION))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0584c855",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd2460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('** Training starts...\\n')\n",
    "model.fit(X_train, Y_train,\n",
    "          validation_data=(X_test, Y_test),\n",
    "          batch_size=TRAIN_BATCH_SIZE, verbose=1,\n",
    "          epochs=TRAIN_EPOCHS)\n",
    "print('\\n** Training completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c465fb4a",
   "metadata": {},
   "source": [
    "#### Evaluate model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799279ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = model.predict(X_test)\n",
    "predicted = np.argmax(Y_predict, axis=1)\n",
    "report = classification_report(np.argmax(Y_test, axis=1), predicted)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ab02ce",
   "metadata": {},
   "source": [
    "### Storing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc6e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving the trained model ...', end='')\n",
    "model_out_file = os.path.join(model_save_dir, 'model2.h5')\n",
    "model.save(model_out_file)\n",
    "print(f'done [{model_out_file}]')\n",
    "\n",
    "print('Saving model metadata ...', end='')\n",
    "metadata_out_file = os.path.join(model_save_dir, 'model2_metadata.json')\n",
    "#\n",
    "model_metadata = {\n",
    "    'label_legend_inverted': labelLegendInverted,\n",
    "    'label_legend': labelLegend,\n",
    "}\n",
    "#\n",
    "json.dump(model_metadata, open(metadata_out_file, 'w'), indent=2)\n",
    "print(f'done [{metadata_out_file}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc7a66",
   "metadata": {},
   "source": [
    "#### Test load-and-apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "\n",
    "from analysis.features2.feature2_extractor import Feature2Extractor\n",
    "\n",
    "#\n",
    "feature2_extractor = Feature2Extractor()\n",
    "loaded_model = models.load_model(model_out_file)\n",
    "loaded_metadata = json.load(open(metadata_out_file))\n",
    "\n",
    "# prediction\n",
    "input_text = 'hi guys download this shady thing if you like free cash and a prize'\n",
    "feats = feature2_extractor.get_features_list(input_text)\n",
    "probabilities = loaded_model.predict(np.array([feats]))[0].tolist()\n",
    "prediction = {\n",
    "    lb: probabilities[lbi]\n",
    "    for lb, lbi in loaded_metadata['label_legend'].items()\n",
    "}\n",
    "#\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
